{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MonReader\n",
    "---\n",
    "## Summary\n",
    "\n",
    "**Data Description:**\n",
    "\n",
    "We collected page flipping video from smart phones and labelled them as flipping and not flipping.\n",
    "\n",
    "We clipped the videos as short videos and labelled them as flipping or not flipping. The extracted frames are then saved to disk in a sequential order with the following naming structure: VideoID_FrameNumber\n",
    "\n",
    "**Goal(s):**\n",
    "\n",
    "Predict if the page is being flipped using a single image.\n",
    "\n",
    "**Success Metrics:**\n",
    "\n",
    "Evaluate model performance based on F1 score, the higher the better.\n",
    "\n",
    "**Bonus(es):**\n",
    "\n",
    "Predict if a given sequence of images contains an action of flipping.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standards\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from scipy import stats\n",
    "import statistics\n",
    "import tensorflow as tf\n",
    "\n",
    "# For Data Import\n",
    "from pathlib import Path\n",
    "\n",
    "# For Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.metrics import classification_report\n",
    "from keras import backend as K\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "\n",
    "# Suppress deprecation warnings\n",
    "#warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "#warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "\n",
    "Image data should be preprocessed before feeding into a computer vision model. Here, we've included normalization and resizing of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pre-processing functions\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image /= 255.0  # normalize to [0,1] range\n",
    "    return image\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    return preprocess_image(image)\n",
    "\n",
    "def load_and_preprocess_from_path_label(path, label):\n",
    "    return load_and_preprocess_image(path), label\n",
    "\n",
    "# Get image paths and labels for training and testing datasets\n",
    "def get_image_paths_and_labels(directory):\n",
    "    flip_image_paths = [str(path) for path in list(Path(directory + '/flip').glob('*.jpg'))]\n",
    "    notflip_image_paths = [str(path) for path in list(Path(directory + '/notflip').glob('*.jpg'))]\n",
    "    flip_labels = [1]*len(flip_image_paths)\n",
    "    notflip_labels = [0]*len(notflip_image_paths)\n",
    "    return flip_image_paths + notflip_image_paths, flip_labels + notflip_labels\n",
    "\n",
    "train_image_paths, train_image_labels = get_image_paths_and_labels(r\"C:\\ref\\images\\training\")\n",
    "test_image_paths, test_image_labels = get_image_paths_and_labels(r\"C:\\ref\\images\\testing\")\n",
    "\n",
    "batch_size = 32 # Define batch size\n",
    "\n",
    "# Create Datasets\n",
    "train_path_ds = tf.data.Dataset.from_tensor_slices((train_image_paths, train_image_labels))\n",
    "train_image_label_ds = train_path_ds.map(load_and_preprocess_from_path_label)\n",
    "train_ds = train_image_label_ds.shuffle(buffer_size=len(train_image_labels)).batch(batch_size)\n",
    "\n",
    "test_path_ds = tf.data.Dataset.from_tensor_slices((test_image_paths, test_image_labels))\n",
    "test_image_label_ds = test_path_ds.map(load_and_preprocess_from_path_label)\n",
    "test_ds = test_image_label_ds.shuffle(buffer_size=len(test_image_labels)).batch(batch_size)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a CNN model\n",
    "\n",
    "model = Sequential() # Base liner layer model\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3))) # 1st layer\n",
    "model.add(MaxPooling2D((2, 2))) # Reduce size of convolutional layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu')) # 2nd layer\n",
    "model.add(MaxPooling2D((2, 2))) # Reduce size of convolutional layer\n",
    "model.add(Flatten()) # Convert to vector for dense layers\n",
    "model.add(Dense(64, activation='relu')) # 3rd layer - dense\n",
    "model.add(Dense(1, activation='sigmoid')) # Output Binary layer: flip or not flip\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "75/75 [==============================] - 103s 1s/step - loss: 0.0422 - accuracy: 0.9866 - precision_m: 0.9893 - recall_m: 0.9856 - f1_m: 0.9863 - val_loss: 0.0535 - val_accuracy: 0.9883 - val_precision_m: 0.9933 - val_recall_m: 0.9839 - val_f1_m: 0.9882\n",
      "Epoch 2/5\n",
      "75/75 [==============================] - 92s 1s/step - loss: 0.0018 - accuracy: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - f1_m: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9950 - val_precision_m: 0.9969 - val_recall_m: 0.9923 - val_f1_m: 0.9944\n",
      "Epoch 3/5\n",
      "75/75 [==============================] - 93s 1s/step - loss: 8.2254e-04 - accuracy: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - f1_m: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9933 - val_precision_m: 0.9971 - val_recall_m: 0.9896 - val_f1_m: 0.9931\n",
      "Epoch 4/5\n",
      "75/75 [==============================] - 93s 1s/step - loss: 2.9518e-04 - accuracy: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - f1_m: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9950 - val_precision_m: 0.9971 - val_recall_m: 0.9908 - val_f1_m: 0.9937\n",
      "Epoch 5/5\n",
      "75/75 [==============================] - 97s 1s/step - loss: 1.8941e-04 - accuracy: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - f1_m: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9933 - val_precision_m: 1.0000 - val_recall_m: 0.9859 - val_f1_m: 0.9926\n",
      "19/19 [==============================] - 7s 281ms/step - loss: 0.0405 - accuracy: 0.9933 - precision_m: 1.0000 - recall_m: 0.9861 - f1_m: 0.9927\n"
     ]
    }
   ],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', precision_m, recall_m, f1_m])\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(train_ds, epochs=5, validation_data=test_ds)\n",
    "\n",
    "# evaluate the model\n",
    "loss, accuracy, precision, recall, f1_score = model.evaluate(test_ds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
