{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p3iwGp-U5RR"
      },
      "source": [
        "# Potential Talents\n",
        "---\n",
        "## Summary\n",
        "**Background:**\n",
        "\n",
        "As a talent sourcing and management company, we are interested in finding talented individuals for sourcing these candidates to technology companies. Finding talented candidates is not easy, for several reasons. The first reason is one needs to understand what the role is very well to fill in that spot, this requires understanding the client’s needs and what they are looking for in a potential candidate. The second reason is one needs to understand what makes a candidate shine for the role we are in search for. Third, where to find talented individuals is another challenge.\n",
        "\n",
        "The nature of our job requires a lot of human labor and is full of manual operations. Towards automating this process we want to build a better approach that could save us time and finally help us spot potential candidates that could fit the roles we are in search for. Moreover, going beyond that for a specific role we want to fill in we are interested in developing a machine learning powered pipeline that could spot talented individuals, and rank them based on their fitness.\n",
        "\n",
        "We are right now semi-automatically sourcing a few candidates, therefore the sourcing part is not a concern at this time but we expect to first determine best matching candidates based on how fit these candidates are for a given role. We generally make these searches based on some keywords such as “full-stack software engineer”, “engineering manager” or “aspiring human resources” based on the role we are trying to fill in. These keywords might change, and you can expect that specific keywords will be provided to you.\n",
        "\n",
        "Assuming that we were able to list and rank fitting candidates, we then employ a review procedure, as each candidate needs to be reviewed and then determined how good a fit they are through manual inspection. This procedure is done manually and at the end of this manual review, we might choose not the first fitting candidate in the list but maybe the 7th candidate in the list. If that happens, we are interested in being able to re-rank the previous list based on this information. This supervisory signal is going to be supplied by starring the 7th candidate in the list. Starring one candidate actually sets this candidate as an ideal candidate for the given role. Then, we expect the list to be re-ranked each time a candidate is starred.\n",
        "\n",
        "**Data Description**\n",
        "\n",
        "The data comes from our sourcing efforts. We removed any field that could directly reveal personal details and gave a unique identifier for each candidate.\n",
        "\n",
        "Attributes:\n",
        "- id : unique identifier for candidate (numeric)\n",
        "- job_title : job title for candidate (text)\n",
        "- location : geographical location for candidate (text)\n",
        "- connections: number of connections candidate has, 500+ means over 500 (text)\n",
        "\n",
        "Output (desired target):\n",
        "- fit - how fit the candidate is for the role? (numeric, probability between 0-1)\n",
        "\n",
        "Keywords: “Aspiring human resources” or “seeking human resources”\n",
        "\n",
        "**Goal(s):**\n",
        "\n",
        "- Predict how fit the candidate is based on their available information (variable fit)\n",
        "\n",
        "**Success Metric(s):**\n",
        "\n",
        "- Rank candidates based on a fitness score.\n",
        "- Re-rank candidates when a candidate is starred.\n",
        "\n",
        "**Bonus(es):**\n",
        "\n",
        "- We are interested in a robust algorithm, tell us how your solution works and show us how your ranking gets better with each starring action.\n",
        "- How can we filter out candidates which in the first place should not be in this list?\n",
        "- Can we determine a cut-off point that would work for other roles without losing high potential candidates?\n",
        "- Do you have any ideas that we should explore so that we can even automate this procedure to prevent human bias?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNGl5eeeVMcv"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os1dIieGpGPB"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "k_wmVoPlU5RV",
        "outputId": "b5be01d1-37e2-403e-d814-6735c19c439f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\danie\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\danie\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\danie\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Standards\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "from scipy import stats\n",
        "\n",
        "# for doc2vec\n",
        "import gensim\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# for cleaning\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "# If running for the first time, download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# for BERT\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "# for ranking algorithm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import ndcg_score\n",
        "\n",
        "# Warnings\n",
        "import warnings\n",
        "\n",
        "# Suppress deprecation warnings\n",
        "#warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "#warnings.filterwarnings('ignore', category=UserWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM0NoQTEVSmv"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5B4l3dHVSCm",
        "outputId": "4c2e3507-7470-47dc-ce65-29c01b41381f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x shape: (104, 3)\n",
            "y shape: (104,)\n"
          ]
        }
      ],
      "source": [
        "# Load the data from a CSV file\n",
        "dataset = pd.read_csv('potential-talents.csv')\n",
        "\n",
        "# Extract only 2 feature columns\n",
        "x = dataset.iloc[:, [0,1,3]].values\n",
        "y = dataset.iloc[:, 4].values\n",
        "\n",
        "# Create a DataFrame with the feature columns\n",
        "df = pd.DataFrame(x, columns=['id','job_title', 'connection'])\n",
        "\n",
        "print(f\"x shape: {x.shape}\")\n",
        "print(f\"y shape: {y.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34L-_uYpZrXu"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUpswEdtZ2OB"
      },
      "source": [
        "## Missing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAJIR7NWZuE8",
        "outputId": "33844ac3-106d-4250-c8cc-8d8784fe7ed3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing Data:\n",
            "id              0\n",
            "job_title       0\n",
            "location        0\n",
            "connection      0\n",
            "fit           104\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Handle missing data\n",
        "missing_data = dataset.isnull().sum()\n",
        "print(\"Missing Data:\")\n",
        "print(missing_data)\n",
        "\n",
        "# Impute missing values\n",
        "#imputer = SimpleImputer(strategy='mean')  # Use mean imputation for numeric features\n",
        "#dataset[numeric_features] = imputer.fit_transform(dataset[numeric_features])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deduplicate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of the DataFrame before removing duplicates: (104, 3)\n",
            "Shape of the DataFrame after removing duplicates: (53, 3)\n",
            "Index reset after removing duplicates.\n"
          ]
        }
      ],
      "source": [
        "# Print the shape of the DataFrame before removing duplicates\n",
        "print(f\"Shape of the DataFrame before removing duplicates: {df.shape}\")\n",
        "\n",
        "# Remove duplicates and print the shape of the DataFrame after removing duplicates\n",
        "df = df.drop_duplicates(subset=['job_title', 'connection'])\n",
        "print(f\"Shape of the DataFrame after removing duplicates: {df.shape}\")\n",
        "\n",
        "# Reset the index and print a success message\n",
        "df = df.reset_index(drop=True)\n",
        "print(\"Index reset after removing duplicates.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgWXOVVpenDE"
      },
      "source": [
        "## Cleaning\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVLqojoaqwyv"
      },
      "source": [
        "### job_title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Xf0VvK0bepoV"
      },
      "outputs": [],
      "source": [
        "# Initialize lemmatizer and stemmer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Define preprocesser\n",
        "def preprocess(document):\n",
        "\n",
        "    document = document.lower() # Convert text to lower case\n",
        "    document = re.sub(r'\\d+', '', document) # Remove numbers\n",
        "    document = re.sub(r'\\W', ' ', document) # Remove punctuation\n",
        "    document = document.strip() # Remove leading/trailing white space\n",
        "\n",
        "    tokens = nltk.word_tokenize(document) # Tokenize into words\n",
        "    tokens = [word for word in tokens if word not in stopwords.words('english')]  # Remove stopwords\n",
        "\n",
        "    # Lemmatize or stem the words\n",
        "    # For lemmatization:\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    # For stemming:\n",
        "    # tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    document = \" \".join(tokens) # Join the processed words back into a single string\n",
        "\n",
        "    return document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fp0tVThQesxx",
        "outputId": "dbb8b575-13d4-4b5d-d2ec-3e424656acff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "w1 becomes: aspiring human resource\n",
            "w2 becomes: seeking human resource\n"
          ]
        }
      ],
      "source": [
        "# Clean columns\n",
        "df['job_title'] = df['job_title'].apply(preprocess)\n",
        "\n",
        "# Preprocess the words before getting their vectors\n",
        "w1 = preprocess(\"Aspiring human resources\")\n",
        "w2 = preprocess(\"seeking human resources\")\n",
        "\n",
        "print(f\"w1 becomes: {w1}\")\n",
        "print(f\"w2 becomes: {w2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyBVbebZqytG"
      },
      "source": [
        "### connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QJJM0AuLq1wM"
      },
      "outputs": [],
      "source": [
        "# Make the \"connection\" column as a numeric column by making \"500+\" to \"500\" and leaving the rest\n",
        "df['connection'] = df['connection'].replace('500+ ', '500').astype(int)\n",
        "df['connection'] = df['connection'].replace('500+', '500').astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VEV0-lLernez"
      },
      "outputs": [],
      "source": [
        "# Scale the \"connection\" column\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Scale the 'connections' column\n",
        "df['connection_scaled'] = scaler.fit_transform(df[['connection']])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Natural Language Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLMAO7Gydbca"
      },
      "source": [
        "## Doc2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9H9xa-jvZ3iP"
      },
      "outputs": [],
      "source": [
        "# Create doc2vec embeddings for all job titles, and w1 (chosen phrases)\n",
        "\n",
        "# Tokenize the job_titles\n",
        "data = [word_tokenize(title) for title in df['job_title']]\n",
        "\n",
        "# Create tagged documents\n",
        "tagged_data = [TaggedDocument(words=_d, tags=[str(i)]) for i, _d in enumerate(data)]\n",
        "\n",
        "# Set-up the model\n",
        "model = Doc2Vec(vector_size=20,      # Dimensionality of the feature vectors\n",
        "                window=2,            # The maximum distance between the current and predicted word within a sentence.\n",
        "                min_count=1,         # Ignores all words with total frequency lower than this.\n",
        "                workers=4,           # Use these many worker threads to train the model\n",
        "                epochs=100)          # Number of iterations (epochs) over the corpus\n",
        "\n",
        "# Build vocabulary from a sequence of sentences\n",
        "model.build_vocab(tagged_data)\n",
        "\n",
        "# Train the model\n",
        "model.train(tagged_data,\n",
        "            total_examples=model.corpus_count,\n",
        "            epochs=model.epochs)\n",
        "\n",
        "# Extract vectors of all job_titles\n",
        "vectors = [model.dv[i] for i in range(len(df['job_title']))]\n",
        "\n",
        "# now 'vectors' contains the doc2vec vectors for each job_title\n",
        "\n",
        "df['doc2vec_embeddings'] = vectors\n",
        "\n",
        "# Infer the vector for each chosen phrase\n",
        "v1 = model.infer_vector(word_tokenize(w1))\n",
        "v2 = model.infer_vector(word_tokenize(w2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2aR_HoJpe4E",
        "outputId": "695d76e4-1af0-4984-9c61-2c9ad38a29bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of Similarities: 53\n"
          ]
        }
      ],
      "source": [
        "# Calculate Cosine Similarity between w1 and each job_title\n",
        "\n",
        "# Initialize an empty list to store the similarities\n",
        "similarities = []\n",
        "\n",
        "# Loop through each job title vector\n",
        "for vec in vectors:\n",
        "    # Reshape vectors to 2D arrays necessary for cosine_similarity function\n",
        "    vec = np.array(vec).reshape(1, -1)\n",
        "    v1 = np.array(v1).reshape(1, -1)\n",
        "\n",
        "    # Calculate similarity and append to the list\n",
        "    sim = cosine_similarity(vec, v1)\n",
        "    similarities.append(sim[0][0])\n",
        "\n",
        "# Now 'similarities' is a list of cosine similarities between 'w1' and each job title.\n",
        "\n",
        "# Add the 'similarities' list as a new column to the dataframe\n",
        "df['similarity'] = similarities\n",
        "\n",
        "print(f\"Size of Similarities: {len(similarities)}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BERT\n",
        "(Bidirectional Encoder Representations from Transformers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained model tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load pre-trained model\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Function to generate BERT embeddings\n",
        "def generate_bert_embeddings(text):\n",
        "    # Add the special tokens for BERT\n",
        "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "    # Tokenize our sentence with the BERT tokenizer.\n",
        "    tokenized_text = tokenizer.tokenize(marked_text)\n",
        "\n",
        "    # Map the token strings to their vocabulary indices.\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "    # Mark each token as belonging to sentence \"1\".\n",
        "    segments_ids = [1] * len(tokenized_text)\n",
        "\n",
        "    # Convert inputs to PyTorch tensors\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "    segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "    # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "    model.eval()\n",
        "\n",
        "    # Predict hidden states features for each layer\n",
        "    with torch.no_grad():\n",
        "        outputs = model(tokens_tensor, segments_tensors)\n",
        "        # `outputs` is a tuple, we only need the token embeddings from the first element of the tuple\n",
        "        encoded_layers = outputs[0]\n",
        "\n",
        "    # Get the embeddings of the [CLS] token as the text embedding\n",
        "    text_embedding = encoded_layers[0][0]\n",
        "\n",
        "    return text_embedding.numpy()  # Convert tensor to numpy array for easier use\n",
        "\n",
        "# Generate BERT embeddings for all job titles and store in a list\n",
        "bert_embeddings = df['job_title'].apply(generate_bert_embeddings).tolist()\n",
        "\n",
        "df['bert_embeddings'] = bert_embeddings\n",
        "\n",
        "# Generate BERT embedding for each chosen phrase\n",
        "w1_bert = generate_bert_embeddings(w1)\n",
        "w2_bert = generate_bert_embeddings(w2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of bert_Similarities: 53\n"
          ]
        }
      ],
      "source": [
        "# Initialize an empty list to store the similarities\n",
        "bert_similarities = []\n",
        "\n",
        "# Loop through each BERT job title vector\n",
        "for bert_vec in bert_embeddings:\n",
        "    # Reshape vectors to 2D arrays necessary for cosine_similarity function\n",
        "    bert_vec = np.array(bert_vec).reshape(1, -1)\n",
        "    w1_bert = np.array(w1_bert).reshape(1, -1)\n",
        "\n",
        "    # Calculate similarity and append to the list\n",
        "    sim = cosine_similarity(bert_vec, w1_bert)\n",
        "    bert_similarities.append(sim[0][0])\n",
        "\n",
        "# Now 'bert_similarities' is a list of cosine similarities between 'w1' and each job title\n",
        "\n",
        "# Add the 'similarities' list as a new column to the dataframe\n",
        "df['bert_similarity'] = bert_similarities\n",
        "\n",
        "print(f\"Size of bert_Similarities: {len(bert_similarities)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwuLdz_-tevp"
      },
      "source": [
        "## Weighted Sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CkLT2ycrtdnA"
      },
      "outputs": [],
      "source": [
        "# Set weights here\n",
        "weight_similarity = 0.8\n",
        "weight_connection = 0.2\n",
        "\n",
        "# Ensure weights add up to 1\n",
        "assert weight_similarity + weight_connection == 1, \"Weights should add up to 1\"\n",
        "\n",
        "# Create the weighted sum column\n",
        "df['ranking'] = weight_similarity * df['similarity'] + weight_connection * df['connection_scaled']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KKPRsJDhvQW_"
      },
      "outputs": [],
      "source": [
        "# Set BERT weights here\n",
        "weight_similarity_bert = 0.8\n",
        "weight_connection = 0.2\n",
        "\n",
        "# Ensure weights add up to 1\n",
        "assert weight_similarity_bert + weight_connection == 1, \"Weights should add up to 1\"\n",
        "\n",
        "# Create the weighted sum column\n",
        "df['bert_ranking'] = weight_similarity_bert * df['bert_similarity'] + weight_connection * df['connection_scaled']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Initial Ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 rankings based on Doc2Vec:\n",
            "\n",
            " id                                                     job_title  ranking\n",
            "  8                                          hr senior specialist 0.825633\n",
            " 27 aspiring human resource management student seeking internship 0.820343\n",
            " 67               human resource staffing recruiting professional 0.819745\n",
            " 71                     human resource generalist scottmadden inc 0.818347\n",
            " 69         director human resource north america groupe beneteau 0.817128\n",
            "  4                           people development coordinator ryan 0.813560\n",
            "103                                            always set success 0.810582\n",
            "  2             native english teacher epik english program korea 0.809023\n",
            "  5                  advisory board member celal bayar university 0.807815\n",
            " 85 rrp brand portfolio executive jti japan tobacco international 0.806603\n",
            "\n",
            "Top 10 rankings based on BERT:\n",
            "\n",
            " id                                                                  job_title  bert_ranking\n",
            " 27              aspiring human resource management student seeking internship      0.923905\n",
            "  8                                                       hr senior specialist      0.920956\n",
            " 67                            human resource staffing recruiting professional      0.917379\n",
            "104                                 director administration excellence logging      0.914063\n",
            " 71                                  human resource generalist scottmadden inc      0.911093\n",
            "  4                                        people development coordinator ryan      0.908201\n",
            "101                                          human resource generalist loparex      0.907506\n",
            " 68                                        human resource specialist luxottica      0.906092\n",
            " 75 nortia staffing seeking human resource payroll administrative professional      0.904601\n",
            " 78                                           human resource generalist schwan      0.903750\n"
          ]
        }
      ],
      "source": [
        "# Sorting by Doc2Vec ranking\n",
        "doc2vec_ranking = df.sort_values('ranking', ascending=False)\n",
        "\n",
        "# Sorting by BERT ranking\n",
        "bert_ranking = df.sort_values('bert_ranking', ascending=False)\n",
        "\n",
        "# Select specific columns\n",
        "doc2vec_ranking = doc2vec_ranking[['id', 'job_title', 'ranking']]\n",
        "bert_ranking = bert_ranking[['id', 'job_title', 'bert_ranking']]\n",
        "\n",
        "# Print top 10 \n",
        "print(\"Top 10 rankings based on Doc2Vec:\\n\")\n",
        "print(doc2vec_ranking.head(10).to_string(index=False))\n",
        "print(\"\\nTop 10 rankings based on BERT:\\n\")\n",
        "print(bert_ranking.head(10).to_string(index=False))\n",
        "\n",
        "# Get the IDs of top 10 candidates based on BERT rankings\n",
        "top10_bert_ids = bert_ranking['id'].head(10).values\n",
        "\n",
        "# Create a new 'starred' column, initially setting all values to False\n",
        "df['starred'] = 0\n",
        "\n",
        "# Set 'starred' to True for top 10 candidates\n",
        "df.loc[df['id'].isin(top10_bert_ids), 'starred'] = 1\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LambdaRank"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (42, 4)\n",
            "y_train shape: (42,)\n",
            "x_test shape: (11, 4)\n",
            "y_test shape: (11,)\n"
          ]
        }
      ],
      "source": [
        "le = LabelEncoder()\n",
        "df['job_title_encoded'] = le.fit_transform(df['job_title'])\n",
        "\n",
        "# Add 'job_title_encoded' to the feature columns\n",
        "x = df[['similarity', 'bert_similarity', 'connection_scaled', 'job_title_encoded']]\n",
        "y = df['starred']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "random_state = 137\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=random_state, shuffle=True)\n",
        "\n",
        "# Visualize the shapes of the training and testing sets\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"x_test shape:\", x_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       similarity  bert_similarity  connection_scaled  job_title_encoded\n",
            "count   53.000000        53.000000          53.000000          53.000000\n",
            "mean     0.704408         0.882758           0.482777          25.132075\n",
            "std      0.175138         0.028989           0.435000          15.245476\n",
            "min     -0.389306         0.833813           0.000000           0.000000\n",
            "25%      0.719630         0.862614           0.086172          12.000000\n",
            "50%      0.750570         0.879211           0.308617          25.000000\n",
            "75%      0.766520         0.896724           1.000000          38.000000\n",
            "max      0.816687         0.952651           1.000000          51.000000\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Summary statistics\n",
        "print(x.describe())\n",
        "\n",
        "# Histograms\n",
        "x.hist()\n",
        "plt.suptitle(\"Histograms of numeric features\")\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.subplots_adjust(left=0.1, right=0.9, bottom=0.1, top=0.9, wspace=0.3, hspace=0.75)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 42\n",
            "[LightGBM] [Info] Number of data points in the train set: 42, number of used features: 3\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[1]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[2]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[3]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[4]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[5]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[6]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[7]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[8]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[9]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[10]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[11]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[12]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[13]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[14]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[15]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[16]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[17]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[18]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[19]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[20]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[21]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[22]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[23]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[24]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[25]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[26]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[27]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[28]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[29]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[30]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[31]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[32]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[33]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[34]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[35]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[36]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[37]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[38]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[39]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[40]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[41]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[42]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[43]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[44]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[45]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[46]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[47]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[48]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[49]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[50]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[51]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[52]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[53]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[54]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[55]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[56]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[57]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[58]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[59]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[60]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[61]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[62]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[63]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[64]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[65]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[66]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[67]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[68]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[69]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[70]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[71]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[72]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[73]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[74]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[75]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[76]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[77]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[78]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[79]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[80]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[81]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[82]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[83]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[84]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[85]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[86]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[87]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[88]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[89]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[90]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[91]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[92]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[93]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[94]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[95]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[96]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[97]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[98]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[99]\tvalid_0's ndcg@10: 1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[100]\tvalid_0's ndcg@10: 1\n"
          ]
        }
      ],
      "source": [
        "group_train = x_train.groupby('job_title_encoded').size().tolist()\n",
        "group_test = x_test.groupby('job_title_encoded').size().tolist()\n",
        "\n",
        "\n",
        "# Create dataset for lightgbm\n",
        "lgb_train = lgb.Dataset(x_train.drop(columns='job_title_encoded'), y_train, group=group_train)\n",
        "lgb_eval = lgb.Dataset(x_test.drop(columns='job_title_encoded'), y_test, group=group_test, reference=lgb_train)\n",
        "\n",
        "\n",
        "# Set parameters for LightGBM.\n",
        "params = {\n",
        "    'objective': 'lambdarank',  # Specify LambdaRank\n",
        "    'metric': 'ndcg',  # Use Normalized Discounted Cumulative Gain (NDCG) for evaluation\n",
        "    'ndcg_eval_at': [10],  # Evaluate the model by the ranking of top 10 candidates\n",
        "    'learning_rate': 0.1,  # The learning rate\n",
        "    'num_leaves': 10,  # The number of leaves in one tree\n",
        "    'min_data_in_leaf': int(0.2*len(df)),  # Minimal number of data in one leaf (20% of current dataset size)\n",
        "}\n",
        "\n",
        "# Train the model\n",
        "gbm = lgb.train(params, lgb_train, num_boost_round=100,valid_sets=lgb_eval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validation\n",
        "\n",
        "The Normalized Discounted Cumulative Gain (NDCG) is calculated as follows:\n",
        "\n",
        "1. DCG (Discounted Cumulative Gain) - The gain is accumulated from the top of the result list to the bottom, with the gain of each result discounted at lower ranks.\n",
        "\n",
        "2. IDCG (Ideal Discounted Cumulative Gain) - Maximum possible DCG for a given set of queries, documents, or rankings.\n",
        "\n",
        "3. NDCG - The ratio of DCG to IDCG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dcg_at_k(r, k):\n",
        "    \"\"\"Score is discounted cumulative gain (dcg)\n",
        "    Relevance is positive real values. Can use binary\n",
        "    as the previous methods.\n",
        "    Example from\n",
        "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
        "    \"\"\"\n",
        "    r = np.asfarray(r)[:k]\n",
        "    if r.size:\n",
        "        return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
        "    return 0.\n",
        "\n",
        "def ndcg_at_k(r, k):\n",
        "    \"\"\"Score is normalized discounted cumulative gain (ndcg)\"\"\"\n",
        "    dcg_max = dcg_at_k(sorted(r, reverse=True), k)\n",
        "    if not dcg_max:\n",
        "        return 0.\n",
        "    return dcg_at_k(r, k) / dcg_max\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NDCG Scores: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Average NDCG at 10: 0.09090909090909091\n"
          ]
        }
      ],
      "source": [
        "# get predictions for test data\n",
        "y_pred = gbm.predict(x_test.drop(columns='job_title_encoded'))\n",
        "\n",
        "# we'll compute the NDCG at 10\n",
        "k = 10\n",
        "\n",
        "# create a new DataFrame for convenience\n",
        "results = pd.DataFrame({'y_true': y_test, 'y_pred': y_pred, 'query': x_test['job_title_encoded']})\n",
        "\n",
        "# sort by 'query' and then by 'y_pred' (predicted relevance)\n",
        "results.sort_values(['query', 'y_pred'], ascending=[True, False], inplace=True)\n",
        "\n",
        "# list to store NDCG scores\n",
        "ndcg_scores = []\n",
        "\n",
        "# get unique queries\n",
        "queries = results['query'].unique()\n",
        "\n",
        "for query in queries:\n",
        "    temp = results[results['query'] == query]\n",
        "    true_relevance = temp['y_true'].values\n",
        "    ndcg_scores.append(ndcg_at_k(true_relevance, k))\n",
        "\n",
        "# compute the average NDCG over all queries\n",
        "avg_ndcg = np.mean(ndcg_scores)\n",
        "print('NDCG Scores:', ndcg_scores)\n",
        "print('Average NDCG at {}: {}'.format(k, avg_ndcg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
